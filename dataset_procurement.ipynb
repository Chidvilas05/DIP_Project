{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ec896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "SEGMENTATION_MODEL = torchvision.models.detection.maskrcnn_resnet50_fpn(weights='DEFAULT')\n",
    "SEGMENTATION_MODEL.eval()\n",
    "\n",
    "OUTPUT_IMAGE_SIZE= 224 #224*224\n",
    "\n",
    "def segment_car(img): \n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    img_tensor = transform(img)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = SEGMENTATION_MODEL([img_tensor])[0]\n",
    "\n",
    "    boxes = predictions['boxes'].cpu().numpy()\n",
    "    labels = predictions['labels'].cpu().numpy()\n",
    "    scores = predictions['scores'].cpu().numpy()\n",
    "    masks = predictions['masks'].cpu().numpy()\n",
    "\n",
    "    biggest_box_car = np.argmax([ (boxes[i][2]-boxes[i][0])*(boxes[i][3]-boxes[i][1]) if labels[i] == 3 else 0 for i in range(len(labels))])\n",
    "    box = boxes[biggest_box_car].astype(int)\n",
    "    mask = masks[biggest_box_car, 0] > 0.5\n",
    "    x0, y0, x1, y1 = box\n",
    "    cropped = img.crop((x0, y0, x1, y1))\n",
    "    masked_np = mask[:,:,None] * img\n",
    "    masked_np = masked_np.astype(np.uint8)\n",
    "\n",
    "    def crop_zero_borders():\n",
    "        zero_top_index = np.where(np.cumsum(np.sum(masked_np,axis=(1,2)))==0)[0]\n",
    "        if(len(zero_top_index)>0):\n",
    "            zero_top_index= max(0,zero_top_index[-1]-5)\n",
    "        else:\n",
    "            zero_top_index=0\n",
    "        zero_bottom_index = np.where(np.cumsum(np.sum(masked_np[::-1],axis=(1,2)))==0)[0]\n",
    "        if(len(zero_bottom_index)>0):\n",
    "            zero_bottom_index = min(masked_np.shape[0],masked_np.shape[0]-zero_bottom_index[-1]+5)\n",
    "        else:\n",
    "            zero_bottom_index=masked_np.shape[0]\n",
    "            \n",
    "        zero_left_index = np.where(np.cumsum(np.sum(masked_np,axis=(0,2)))==0)[0]\n",
    "        if(len(zero_left_index)>0):\n",
    "            zero_left_index= max(0,zero_left_index[-1]-5)\n",
    "        else:\n",
    "            zero_left_index=0\n",
    "        zero_right_index = np.where(np.cumsum(np.sum(masked_np[:,::-1],axis=(0,2)))==0)[0]\n",
    "        if(len(zero_right_index)>0):\n",
    "            zero_right_index = min(masked_np.shape[1],masked_np.shape[1]-zero_right_index[-1]+5)\n",
    "        else:\n",
    "            zero_right_index=masked_np.shape[1]\n",
    "        return zero_top_index, zero_bottom_index, zero_left_index, zero_right_index\n",
    "    \n",
    "    cropped_indices = crop_zero_borders()\n",
    "    masked_np = masked_np[cropped_indices[0]:cropped_indices[1],cropped_indices[2]:cropped_indices[3],:]\n",
    "    masked_pil = Image.fromarray(masked_np)\n",
    "    return masked_pil\n",
    "\n",
    "def transform_image(img):\n",
    "    img = img.convert(\"RGB\")\n",
    "    img = segment_car(img)\n",
    "    width, height = img.size\n",
    "\n",
    "    if(width<OUTPUT_IMAGE_SIZE and height<OUTPUT_IMAGE_SIZE):\n",
    "        padding = (0, 0, OUTPUT_IMAGE_SIZE - width, OUTPUT_IMAGE_SIZE - height)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Pad(padding=padding, fill=0),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.ToPILImage()\n",
    "        ])\n",
    "        img = transform(img)\n",
    "        return img\n",
    "    resize_shape = (OUTPUT_IMAGE_SIZE,int((OUTPUT_IMAGE_SIZE/height)*width)) if height>=width else (int((OUTPUT_IMAGE_SIZE/width)*height), OUTPUT_IMAGE_SIZE)\n",
    "    padding = (0, 0, OUTPUT_IMAGE_SIZE - resize_shape[1], OUTPUT_IMAGE_SIZE - resize_shape[0])\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(resize_shape),\n",
    "        transforms.Pad(padding=padding, fill=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.ToPILImage()\n",
    "    ])\n",
    "    return transform(img)\n",
    "\n",
    "main_dir = \"./stanford_cars/\"\n",
    "out_dir = \"./transformed_stanford_cars_rough/\"\n",
    "\n",
    "\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    split_in = os.path.join(main_dir, split)\n",
    "    split_out = os.path.join(out_dir, split)\n",
    "\n",
    "    for root, dirs, files in os.walk(split_in):\n",
    "        rel_path = os.path.relpath(root, split_in)\n",
    "        target_root = os.path.join(split_out, rel_path)\n",
    "        os.makedirs(target_root, exist_ok=True)\n",
    "\n",
    "        for f in files:\n",
    "            if not f.lower().endswith(\".jpg\"):\n",
    "                continue\n",
    "\n",
    "            in_path = os.path.join(root, f)\n",
    "            out_path = os.path.join(target_root, f)\n",
    "\n",
    "            img = Image.open(in_path)\n",
    "            img_t = transform_image(img)\n",
    "            img_t.save(out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mlenv)",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
